<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>R&D: Render Engine</title>
<link rel="stylesheet" href="../style.css" />
</head>

<header>
  <a href='../index.html'>
    <img src="../icons/logo.png" alt="Website Logo" class="logo">
  </a>

  <a href="https://github.com/AndrewWhatling" target="_blank">
    <img src="../icons/github.svg" alt="Github link" class="github">
  </a>

  <a href="https://www.linkedin.com/in/andrew-whatling-2704a6259" target="_blank">
    <img src="../icons/linkedin.svg" alt="Linkedin link" class="linkedin">
  </a>
  
</header>

<body>
  
  <div class="container portfolio-container">

    <div class="portfolio-text-double box">
      <h2>Helix - Custom CPU Based Render Engine</h2>
    </div>

    <div class="portfolio-photo-hero">
      <img src="../images/renders/hero_render.png" alt="Render" />
    </div>

    <div class="portfolio-text-double box">
      <p>
        <br>
        Helix is a CPU rendering software I started briefly in summer, and since late September 2025, have
        dedicated a lot more time to. There were several reasons as to why I wanted to take on this
        project, I was originally inspired by Sebastian Lague's "Coding Adventure" series, especially
        his raytracer and fluid solver projects.
        <br><br>
      </p>
      <p>
        This project also opened up a variety of learning opportunities and new challenges for me. At the time,
        I had recently gotten a new laptop, and setup Arch Linux for the first time. As well as this, I also started
        using Neovim, a text editor with a lot of keyboard-centric flexibility and a steep learning curve. This
        project gave me the perfect excuse to sink hours into learning, as well as getting comfortable with all of
        these new concepts.
      </p>
      <p>
        <br>
        Now one of the first questions I get when I talk about my render engine is 'Why call it "Helix?"'.
        Whenever I imagine the word helix, the first thing that comes to mind is DNA, or a "double helix".
        This project was my first time using C++, I wanted to challenge myself, and had the drive to create
        this project, so having to learn a new programming language wasn't going to stop me. One of the first
        questions I had when first learning C++ was, "What's a double?", turns out it's a float with double the
        precision, and that's where the idea first came from to call it Helix, and it's stuck ever since.
      </p>
      <p>
        <br>
        Below are my latest renders, as well as the journey that got me here.
      </p>
    </div>
    
    <div class="portfolio-text-double box">
      <h2>Data Passes</h2>
      <h3>
        Current working passes - Cryptomatte object/material, Depth, World space Position, 
        Normals and Camera Facing Ratio.
      </h3>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/data_pass_cryptomatte.png" alt="Cryptomatte" />
      <p>Cryptomatte</p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/data_pass_depth.png" alt="Depth" />
      <p>Depth</p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/data_pass_world_space_position.png" alt="World Space Position" />
      <p>World Space Position</p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/data_pass_normals.png" alt="Normals" />
      <p>Normals</p>
    </div>

    <div class="portfolio-photo-double">
      <img src="../images/renders/data_pass_facing_ratio.png" alt="Camera Facing Ratio" />
      <p>Camera Facing Ratio</p>
    </div>

    <div class="portfolio-text-double box">
      <h2>Depth Of Field</h2>
      <h3>
        Using a thin-lens camera model, default settings for the Black Magic Mini Ursa 4.6K.
      </h3>
    </div>

    <div class="portfolio-photo-double">
      <img src="../images/renders/two_dragons_fov_30_2025_oct_27th_10_38.png" alt="Render" />
    </div>

    <div class="portfolio-text-double box">
      <h2>Material Types</h2>
      <h3>
        Current working Materials - Lambertian (Matte), Metallic, Dielectric (Glass) and Emissive.
      </h3>
    </div>
    
    <div class="portfolio-photo">
      <img src="../images/renders/purple_dragon.png" alt="Render" />
      <p>Dielectric (Glass)</p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/lambert_two_dragons_400_primary_2025_oct_27th_10_37.png" alt="Render" />
      <p>Lambertian (Matte)</p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/metallic_two_dragons_400_primary_2025_oct_27th_11_06.png" alt="Render" />
      <p>Metallic</p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/sphere_light_2025_oct_27th_16_01.png" alt="Render" />
      <p>Emissive</p>
    </div>


    <div class="portfolio-text-double box">
      <h2>The Journey</h2>
    </div>

    <div class="portfolio-text box">
      <p>
        I started my render engine off by initially following along a series called "Raytracing in one weekend." 
        I ran through the initial few chapters of that series. This started with creating very basic images, and 
        exporting through a format called PPM. After that was adding a basic sphere into the scene, not as geometry,
        but as the mathematical representation. Once that was working, I added basic anti-aliasing and reading of what
        would be the normals of the sphere, and that finally lead to the image you see here.
      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/antialiasing_2025_sept_30th_12_08.png" alt="Sphere with normals " />
    </div>

    <div class="portfolio-text box">
      <p>
        Once that was complete, the next step was to actually get some form of basic shading. I used a very basic
        shading model to start off with, and the first material type I went with was "Lambertian", a lambert shader, 
        commonly refered to as "Matte shading". This refers to a perfectly diffuse material.
      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/lambert_shadows_2025_oct_01st_01_41.png" alt="Lambert material" />
    </div>

    <div class="portfolio-text box">
      <p>
        This wasn't without issue however. During this I had a error in my code when it came to the calculation of 
        how ambient light should interact with the sphere's that I had. This resulted in the spheres coming out as 
        a flat grey color with no observable depth to them.
      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/greyball_no_shadows_2025_oct_01st_01_03.png" alt="Greyballs no depth" />
    </div>

    <div class="portfolio-text box">
      <p>
        The next material type on the list was metals. The shading model I was using took in 2 parameters for metals. 
        First was the color of the metal in RGB, and the second was a 0 to 1 range value called "Fuzz", essentially how 
        blurred the metal's reflection was.
      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/metal_lambertian_2025_oct_02nd_14_27.png" alt="Metal spheres" />
    </div>

    <div class="portfolio-text box">
      <p>
        After that was programming in a transparent material. The type of transparency I am using is a pure Dielectric model.
        More specifically I am only using Index of Refraction (IOR) to affect the level of transparency that the material has.
        I decided to add a second sphere within the first glass sphere, so that the material can act as though it has thickness,
        rather than just being a solid block of glass.
      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/dialectrics_bubble_2025_oct_05th_22_06.png" alt="Glass bubble sphere" />
    </div>

    <div class="portfolio-text box">
      <p>
        Once I had those materials sorted, it was time to make the camera movable. The main challenge with this was that in order 
        to render objects, you first have to convert the world from world space to camera space (space where the camera is at the 
        center of the world), and from there you then convert to 2D pixel space, so applying a transformation to the camera meant 
        adding the world to camera space transformation as well.
      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/camera_lookat_oct_07th_22_14.png" alt="Camera moved" />
    </div>

    <div class="portfolio-text box">
      <p>
        After making the camera movable, the next thing was to get depth of field working, make the scene feel a bit less CG, as much 
        as you can at this stage anyway. The method used for this was to take the sample position for each pixel, and depending on the 
        field of view given (setting up a camera lens model for DOF will come later), as well as the distance from the focal plane to 
        the current ray of light's length before hitting an object, adds an offset in each direction, thus blurring the image to give 
        depth of field.
      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/depth_of_field_2025_oct_07th_23_26.png" alt="Depth of Field" />
    </div>

    <div class="portfolio-text box">
      <p>
        And with that, I had finished the "Raytracing in One Weekend" Volume One. I had perfect sphere's rendering in all sorts of 
        basic materials, but there was something (actually a lot of "somethings") missing from the render engine. I had a quick glance 
        through the other books of the same series, but ultimately none of them described how to take the next step that I wanted to
        take, and so it was finally time to drop the guidebook and see what happens. Now the real question, what's the next step?
      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/raytracing_in_one_weekend_complete_2025_oct_08th_03_06.png" alt="Raytracing in One Weekend Complete Render" />
    </div>

    <div class="portfolio-text box">
      <p>
        GEOMETRY! Specifically I wanted to get .Obj files loaded into my scene, USD and the rest can come later but for now I just 
        want models in my scene. Now this involved a few different steps before getting it working. Step one, I needed a way to actually 
        read the Obj files into my render engine. Step two, converting those models into something that my render engine can use. 
        Finally step three, using those models to create something in my image, and in this case I went back to square one right at the 
        start of Raytracing in One Weekend, but from the angle of implementing Obj instead of spheres, start in a small capacity and then 
        scale up to production seemed like the best way to handle this challenge.
      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/obj_loaded_2025_oct_12th_03_28.png" alt="Obj Loaded" />
    </div>

    <div class="portfolio-text box">
      <p>
        For loading the .Obj file, luckily it's essentially just a text file with a specific formatting for vertices, normals, uvs and 
        faces. Through C++ I open the file line by line, and check if the first string of characters before a whitespace is either "v"
        (vertex, the position of the point), "vt" (vertex texture, more commonly it's your UV attribute), "vn" (vertex normal) or "f" 
        (the face the specified vertices make up). As I check through them I store them in a custom class I have setup, which just adds 
        them to specific lists (in C++ this is adding to a "vector", which is a dynamically sized list in C++, but for all intensive 
        purposes I'm going to refer to them as lists, as that will be less confusing for anyone familar with 3D who start reading about
        a vector with over 100 components).<br><br>

        I will get to how the creating faces for the render engine to use works later down the line when I start talking about implementing
        quads into the render engine, but for now, the idea was to only give my render engine triangles to work with, and then I just took 
        the first 3 points and made a triangle out of them using the lists I gathered above.
      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/engine/load_obj.png" alt="Load Obj Code" />
    </div>

    <div class="portfolio-text box">
      <p>
        Now for the last part of this, which is just figuring out if the triangles I have intersect with the ray of light currently being 
        fired from the camera. At this point I want to quickly cover something, the way light works in a raytracer is a bit strange. Rather 
        than a light firing rays in all directions, praying that one of those rays hits something, we instead shoot rays from the camera, 
        and have them bounce around in the scene until either a set number of bounces is reached, or if a light source is hit. There aren't 
        any light sources aside from just an ambient light in the scene at the moment and so it's just until the bounce limit is reached.<br><br>

        With that out the way, ray intersection of triangles. Luckily for me this has been studied a LOT and so we have a fun little equation 
        for calculating just this, "Barycentric Coordinates". The idea here is we take the 3 points, and then weight their average influence 
        on our triangle, all of which adds up to a total of 1. From here we can calculate that any position within the triangle will have a 
        positive value, and anything outside will have a negative value, and we don't have to worry about any kind of twisting since a triangle 
        always sits on it's given plane, meaning no matter how much you try, you can't twist it over itself, unlike something like a quad.
        Finally we then check if the ray position ever passes through a positive coordinate, and if it does, we have a hit.
      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/engine/barycentric_coordinates.png" alt="Barycentric Coordinates Code" />
    </div>

    <div class="portfolio-text box">
      <p>
        Next up, I wanted to give my mesh some color, same as before I started with normals rather than a more complex material. The reason 
        for this is so I don't have to worry about calculating how light bounces around my scene and off my geometry, I can just see if it 
        does hit, and if it does then set it to the value of the normals.
      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/face_normals_2025_oct_13th_02_22.png" alt="Obj Face Normals" />
    </div>

    <div class="portfolio-text box">
      <p>
        Now that I know that's working, I decided it was finally time to start looking at adding an actual material to my mesh. Lucky for 
        me it turns out there really wasn't much difference at all with the math from one to another, it was just a matter of setting up 
        my triangle class so that it could be assigned a material.
      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/flat_shaded_2025_oct_13th_03_01.png" alt="Obj Flat Shaded" />
    </div>

    <div class="portfolio-text box">
      <p>
        Next was going through and recreating my scene with multiple objects. More specifically I found having a matte groundplane, along 
        with a matte, glass and metallic sphere proved to be quite a nice testing ground for my render engine, at least at this scale anyway.<br><br>

        Now sadly while it may sound like this has been smooth sailing so far, it really wasn't. This render is actually a good example of 
        one of the issues I had, and it steps from the fact that just because my code doesn't error, doesn't mean the math behind it is working
        as it should be. It may be a bit hard to see, but towards all the poles on the geometry (the part of the faces nearest the points), you 
        should be able to see a wierd bit of banding happening, where there's this curved shadow. It's easiest to see at the bottom pole of the 
        center model.<br><br>

        This was caused from something really silly, I wasn't normalising my ray when I fired it from the camera, which I believe meant that 
        lights shooting from the edge of the scene were bouncing around in too large an increment compared to the center pixels, and so they 
        caused uneven bounces, ultimately leading to that artifact there.
      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/obj_lambertian_metallic_dielectric_2025_oct_15th_04_19.png" alt="Obj Basic Materials" />
    </div>

    <div class="portfolio-text box">
      <p>
        Alright and here's the fixed version, actually if you look between the render here and the one above, you can start playing spot 
        the difference with how many things were actually being affected because of just how long the length of a light ray was.
      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/shadow_banding_fixed_2025_oct_18th_21_46.png" alt="Shadow Banding Fixed" />
    </div>

    <div class="portfolio-text box">
      <p>
        Alright I'm going to blaze through this next bit as you've seen it already, this time thought I was aiming to get a larger mesh 
        working. My scene at this point was maybe 100 triangles if I am being generous. I wanted to render a chinese dragon model that 
        often gets used for benchmarking and R&D tests, and that full mesh is ~800K polygons, so slightly more that I currently have on 
        hand, but don't worry, light work my render engine's got this! Annnnnnnnd it wouldn't even render a pixel after 10 minutes, nice.<br><br>

        Alright baby steps, I lowered my expectations for the minute and decided to go with a roughly ~800 poly mesh, much lighter but 
        even this was a struggle, and so my next steps was optimisation to try and reach my goal of 1 million polygons. 
      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/dragon_low_loaded_2025_oct_12th_04_14.png" alt="Dragon Low Loaded" />
    </div>

    <div class="portfolio-text box">
      <p>
        Now my first optimisation technique I used was called multi-threading. Essentially I was only using one core on my laptop at the 
        time, when it's so much faster to use all of them, in my case I was going from 1 core to 24, so 24 times the number of pixels 
        rendering at one time. Now this doesn't mean that you get 24x the performance, as nice as that would be, it's roughly 6x faster 
        but can be up to 10x depending on what I was doing when rendering. Still not nearly enough for that dragon mesh, great that I can 
        do 24 pixels at once but if I can't even get one to render whats the use putting 24 of them on to not do anything.
      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/normal_dragon_2025_oct_13th_03_23.png" alt="Dragon Low Normals" />
    </div>

    <div class="portfolio-text box">
      <p>
        As for multi-threading specifically. I'm setting up a threadpool (a class that automatically manages all the threads on my laptop)
        and from there I have different functions that I call at different times in the rendering process. What that means is that when a 
        job starts, my threadpool gets all the workers, and then one by one will asign them a task from that job, and will remove them from 
        the current available pool. Then when a worker finishes their task, they will feed back the result, then clean up any residual data,
        before finally being added back to the active pool and the cycle starts all over again until the job is complete.
      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/albedo_dragon_low_2025_oct_13th_04_22.png" alt="Dragon Low Shaded" />
    </div>

    <div class="portfolio-text box">
      <p>
        Alright time for some more optimisation. This time I was getting a mesh of roughly 8K polygons working, which meant I needed to finally 
        start looking at a very powerful algorithm for speeding up calculations like these, A Bounding Volume Hierarchy, or BVH for short.
      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/dragon_mid_2025_oct_25th_03_04.png" alt="Dragon Mid Shaded" />
    </div>

    <div class="portfolio-text box">
      <p>

      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/dragon_high_NaN_2025_oct_26th_02_20.png" alt="Dragon High Shaded" />
    </div>

    <div class="portfolio-text box">
      <p>

      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/lambert_two_dragons_400_primary_2025_oct_27th_10_37.png" alt="Lambert Two Dragons" />
    </div>

    <div class="portfolio-text box">
      <p>

      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/two_dragons_fov_30_2025_oct_27th_10_38.png" alt="Two Dragons Field Of View" />
    </div>

    <div class="portfolio-text box">
      <p>

      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/sphere_light_2025_oct_27th_16_01.png" alt="Sphere Light Dragons" />
    </div>

    <div class="portfolio-text box">
      <p>

      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/metallic_two_dragons_400_primary_2025_oct_27th_11_06.png" alt="Metallic Two Dragons" />
    </div>

    <div class="portfolio-text box">
      <p>

      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/cornell_dragon_01_2025_oct_27th_23_18.png" alt="Cornell Box Dragon" />
    </div>

    <div class="portfolio-text box">
      <p>

      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/purple_dragon.png" alt="Purple Dragon" />
    </div>

    <div class="portfolio-text box">
      <p>

      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/data_pass_depth.png" alt="Data Pass Depth" />
    </div>

    <div class="portfolio-text box">
      <p>

      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/data_pass_normals.png" alt="Data Pass Normals" />
    </div>

    <div class="portfolio-text box">
      <p>

      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/data_pass_world_space_position.png" alt="Data Pass World Space Position" />
    </div>

    <div class="portfolio-text box">
      <p>

      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/data_pass_facing_ratio.png" alt="Data Pass Facing Ratio" />
    </div>

    <div class="portfolio-text box">
      <p>

      </p>
    </div>

    <div class="portfolio-photo">
      <img src="../images/renders/data_pass_cryptomatte.png" alt="Data Pass Cryptomatte" />
    </div>



    <div style="height: 1px;"></div>
  </div>
  


</body>

</html>
